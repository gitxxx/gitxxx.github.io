<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.9.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="大数据、信息安全、数据挖掘、树莓派"><title>Spark Streaming集成Kafka方式 | fangbb的博客</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/donate.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark Streaming集成Kafka方式</h1><a id="logo" href="/.">fangbb的博客</a><p class="description">得之我幸,失之我命</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark Streaming集成Kafka方式</h1><div class="post-meta">Apr 25, 2017<span> | </span><span class="category"><a href="/categories/流处理/">流处理</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#介绍"><span class="toc-number">1.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Receiver"><span class="toc-number">2.</span> <span class="toc-text">Receiver</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#依赖"><span class="toc-number">2.1.</span> <span class="toc-text">依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码"><span class="toc-number">2.2.</span> <span class="toc-text">代码</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Direct"><span class="toc-number">3.</span> <span class="toc-text">Direct</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#依赖-1"><span class="toc-number">3.1.</span> <span class="toc-text">依赖</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#代码-1"><span class="toc-number">3.2.</span> <span class="toc-text">代码</span></a></li></ol></li></ol></div></div><div class="post-content"><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>使用Spark Streaming接收Kafka的数据，有如下两种方式：</p>
<ul>
<li>Receiver</li>
<li>Direct</li>
</ul>
<p>Receiver和Direct对比：</p>
<table>
<thead>
<tr>
<th style="text-align:center">对比</th>
<th style="text-align:center">Receiver API</th>
<th style="text-align:center">Direct API</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">吞吐量</td>
<td style="text-align:center">Receiver模式下为保证零数据丢失，开启WAL，因为数据有效地被复制两次，所以是低效的</td>
<td style="text-align:center">因为没有Receiver，所以不需要Ahead Logs，吞吐量高</td>
</tr>
<tr>
<td style="text-align:center">并行性</td>
<td style="text-align:center">Kafka中的topic partition与Spark Streaming中生成的RDD partition不相关，增加消费topic partition的线程数，只会增加Receiver接收数据的速度。在处理数据时不会增加Spark的并行性。</td>
<td style="text-align:center">Kafka和RDD分区之间存在一对一映射，将从Kafka并行读取数据</td>
</tr>
<tr>
<td style="text-align:center">可靠性</td>
<td style="text-align:center">打开WAL只能保证at-least-once，不能保证Exactly-once，在一些故障下一些记录被消耗两次的机会很小。这是因为Spark Streaming可靠接收的数据与Zookeeper跟踪的偏移之间存在不一致。</td>
<td style="text-align:center">offsets由Spark Streaming在其checkpoints内跟踪。这消除了Spark Streaming和Zookeeper / Kafka之间的不一致，所以尽管失败了，但是每个记录会被Spark Streaming有效地接收一次。</td>
</tr>
</tbody>
</table>
<p>下面会详细介绍两种方式</p>
<h1 id="Receiver"><a href="#Receiver" class="headerlink" title="Receiver"></a>Receiver</h1><p>Receiver通过Kafka的<strong>high-level consumer API</strong>实现的，编程实现简单。通过Receiver从Kafka接收的数据,存储在Spark executor中，然后由Spark Streaming启动的jobs处理数据。</p>
<p>在默认配置下，在失败时可能会丢失数据（请参阅接收器的可靠性）。为确保零数据丢失，必须另外启用Spark Streaming中的Ahead Logs。接收数据时，同时会将收到的Kafka数据写入HDFS的Ahead Logs中，以便在发生故障时恢复所有数据。</p>
<p>下面介绍如何在streaming中使用这种方法</p>
<h2 id="依赖"><a href="#依赖" class="headerlink" title="依赖"></a>依赖</h2><p>在pom.xml文件中添加如下依赖：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-8_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.streaming.kafka._</span><br><span class="line">val kafkaStream = KafkaUtils.createStream(streamingContext,[ZK地址], [consumer<span class="built_in"> group </span>id], [per-topic number of Kafka partitions <span class="keyword">to</span> consume])</span><br></pre></td></tr></table></figure>
<p>解释：</p>
<ul>
<li>第四个参数含义：每个topic的分区被消费时，所使用的线程数。</li>
</ul>
<p>例子：<a href="https://github.com/apache/spark/blob/v2.0.1/examples/src/main/scala/org/apache/spark/examples/streaming/KafkaWordCount.scala" target="_blank" rel="noopener">KafkaWordCount</a></p>
<p>注意：</p>
<ul>
<li>Kafka中的topic partition与Spark Streaming中生成的RDD partition不相关。因此，使用KafkaUtils.createStream()增加消费topic partition的线程数，只会增加Receiver接收数据的速度。<strong>在处理数据时不会增加Spark的并行性</strong>。</li>
<li>使用多个Receiver并行接收不同Topic及不同Group下的数据。</li>
<li>如果使用HDFS启用了Ahead Logs，则接收到的数据已存在副本。因此，需要指定数据的存储级别：StorageLevel.MEMORY_AND_DISK_SER（即使用 KafkaUtils.createStream(…, StorageLevel.MEMORY_AND_DISK_SER)）。</li>
</ul>
<h1 id="Direct"><a href="#Direct" class="headerlink" title="Direct"></a>Direct</h1><p>在Spark 1.3中引入了这种新的无接收器的“direct”方法，以确保更强的端到端保证。代替使用Receiver来接收数据，该方法周期性地查询Kafka以获得每个topic+partition中的最新偏移量，并且相应地定义要在每个batch中处理的偏移范围。</p>
<p>当启动处理数据的作业时，Kafka的<strong>simple consumer API</strong>用于从Kafka读取定义的偏移范围（类似于从文件系统读取文件）。</p>
<p>注意:</p>
<ul>
<li>Direct在Spark 1.3中针对Scala和Java API引入，</li>
<li>Direct在Spark 1.4中针对Python API引入。</li>
</ul>
<p>与基于Receiver的方法相比，该方法具有以下优点：</p>
<ul>
<li><strong>简化并行性</strong>：不需要创建多个输入Kafka streams和联合（union）它们。使用directStream方式，Spark Streaming将创建与要消费的Kafka partitions一样多的RDD partitions，这将从Kafka并行读取数据。因此，Kafka和RDD分区之间存在一对一映射，这更容易理解和调整。</li>
<li><strong>效率</strong>：在Receiver方法中实现零数据丢失需要将数据存储在Ahead Logs中，该日志进一步复制数据。这实际上是低效的，因为数据有效地被复制两次 - 一次是Kafka，另一次是写入Ahead Logs。Direct消除了这个问题，因为没有Receiver，所以不需要Ahead Logs。只要Kafka中数据保留足够长时间，消息可以从Kafka恢复。</li>
<li><strong>Exactly-once语义</strong>：Receiver方法使用Kafka的high-level API在Zookeeper中存储消耗的偏移量。这是传统上消费Kafka数据的方式。虽然这种方法（与Ahead Logs结合）可以确保零数据丢失（即至少一次【at-least once 】 语义），但是在一些故障下，有可能一些记录被消耗两次。这是因为Spark Streaming可靠接收的数据与Zookeeper跟踪的偏移之间存在不一致（比如streaming application在处理某个batch内已接收到的数据的过程中挂掉，但是数据已经处理了一部分，但这种情况下无法将已处理数据的 offsets 更新到 Zookeeper 中，下次重启时，这批数据将再次被消费且处理。）。因此，在Direct中，我们不使用Zookeeper ，而是使用简单的Kafka API。offsets由Spark Streaming在其checkpoints内跟踪。<strong>这消除了Spark Streaming和Zookeeper / Kafka之间的不一致，所以尽管失败了，但是每个记录会被Spark Streaming有效地接收一次。</strong></li>
</ul>
<p><strong>为了实现输出结果的一次性语义，将数据保存到外部数据存储的输出操作必须是<font color="red">幂等</font>的，或者是<font color="red">保存结果和偏移量的原子事务</font></strong></p>
<p>注意：</p>
<ul>
<li>这种方法的一个缺点是它不更新Zookeeper中的偏移，因此基于Zookeeper的Kafka监控工具将不会显示进度。但是，您可以在每个批处理中访问由此方法处理的偏移量，并自己更新Zookeeper。</li>
</ul>
<p>下面介绍如何在streaming中使用这种方法</p>
<h2 id="依赖-1"><a href="#依赖-1" class="headerlink" title="依赖"></a>依赖</h2><p>在pom.xml文件中添加如下依赖：<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.spark<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spark-streaming-kafka-0-8_2.11<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h2><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.streaming.kafka._</span><br><span class="line">import org.apache.spark.streaming.kafka.KafkaUtils</span><br><span class="line">val directKafkaStream = KafkaUtils.createDirectStream[<span class="string">[key class</span>], [<span class="string">value class</span>], [<span class="string">key decoder class</span>], [<span class="string">value decoder class</span>] ](streamingContext, [map of Kafka parameters], [set of topics to consume])</span><br></pre></td></tr></table></figure>
<p>还可以将messageHandler传递给createDirectStream，以访问包含有关当前消息的元数据的MessageAndMetadata，并将其转换为任何所需类型。 请参阅API文档和示例。<br>在Kafka参数中，您必须指定：<strong>metadata.broker.list</strong>或者<strong>bootstrap.servers</strong>。  </p>
<p>默认情况下，它将从每个Kafka分区的最新偏移开始消耗。 如果将Kafka参数中的配置<strong>auto.offset.reset</strong>设置为<strong>smallest</strong>，那么它将从最小偏移开始消耗。</p>
<p>注意：</p>
<ul>
<li>HasOffsetRanges的类型转换只会在directKafkaStream调用的第一个方法中完成，而不是后面的方法链。你可以使用transform()而不是foreachRDD()作为第一个方法调用，以便访问偏移量，然后调用其他Spark方法。然而，请注意，RDD分区和Kafka分区之间的一对一映射在任何shuffle或repartition的方法（比如：reduceByKey()或window()）之后不会保留。</li>
<li>由于此方法不使用Receivers，标准接收器相关（即spark.streaming.Receiver.*形式的配置）将不适用于通过此方法创建的输入DStreams（将应用于其他输入DStreams）。相反，请使用配置spark.streaming.kafka.*. 一个重要的配置项是：spark.streaming.kafka.maxRatePerPartition，它是每个Kafka partition 将被此direct API读取的最大速率（每秒消息数）。</li>
</ul>
<p>例子：<a href="https://github.com/apache/spark/blob/v2.0.1/examples/src/main/scala/org/apache/spark/examples/streaming/DirectKafkaWordCount.scala" target="_blank" rel="noopener">DirectKafkaWordCount</a></p>
<p>参考：<a href="http://spark.apache.org/docs/2.0.1/streaming-kafka-0-8-integration.html" target="_blank" rel="noopener">streaming-kafka-0-8-integration</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://fangbinbin.com/2017/04/25/Spark Streaming集成Kafka方式/" data-id="cjxyiphsq002618i2na8wucma" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Kafka/">Kafka</a><a href="/tags/Spark-Streaming/">Spark Streaming</a></div><div class="post-nav"><a href="/2017/04/26/Kafka使用/" class="pre">Kafka使用</a><a href="/2017/04/24/Kafka概念/" class="next">Kafka概念</a></div><div class="post-donate"><div id="donate_board" class="donate_bar center"><a id="btn_donate" href="javascript:;" title="打赏" class="btn_donate"></a><div class="donate_txt"> &uarr;<br>此文有用? 求鼓励!<br></div></div><div id="donate_guide" class="donate_bar center hidden"><img src="/images/wxzf.jpg" title="微信打赏"></div><script type="text/javascript">document.getElementById('btn_donate').onclick = function(){
    $('#donate_board').addClass('hidden');
    $('#donate_guide').removeClass('hidden');
}</script></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="search" name="word" maxlength="20" placeholder="Search"><input type="hidden" name="si" value="http://fangbinbin.com"><input name="tn" type="hidden" value="bds"><input name="cl" type="hidden" value="3"><input name="ct" type="hidden" value="2097152"><input name="s" type="hidden" value="on"></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/ES/">ES</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">6</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/知识图谱/">知识图谱</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Spark/">Spark</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/指导/">指导</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂谈/">杂谈</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/流处理/">流处理</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/系统/">系统</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/">编程</a><span class="category-list-count">3</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/编程/爬虫/">爬虫</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程/语言/">语言</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/编程语言/">编程语言</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/ES/" style="font-size: 22.5px;">ES</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/Kafka/" style="font-size: 25px;">Kafka</a> <a href="/tags/ML/" style="font-size: 20px;">ML</a> <a href="/tags/MLeap/" style="font-size: 17.5px;">MLeap</a> <a href="/tags/NLP/" style="font-size: 25px;">NLP</a> <a href="/tags/Markdown/" style="font-size: 15px;">Markdown</a> <a href="/tags/特征/" style="font-size: 15px;">特征</a> <a href="/tags/网站/" style="font-size: 15px;">网站</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/登陆/" style="font-size: 15px;">登陆</a> <a href="/tags/Spark/" style="font-size: 25px;">Spark</a> <a href="/tags/Spark-Streaming/" style="font-size: 25px;">Spark Streaming</a> <a href="/tags/技能图谱/" style="font-size: 15px;">技能图谱</a> <a href="/tags/系统/" style="font-size: 15px;">系统</a> <a href="/tags/虚拟机/" style="font-size: 15px;">虚拟机</a> <a href="/tags/杂谈/" style="font-size: 15px;">杂谈</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/04/29/Spark SQL架构/">Spark SQL剖析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/25/Spark两种Stream引擎/">Spark两种Stream引擎</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/24/MLeap实例篇/">MLeap实例篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/01/MLeap使用篇/">MLeap使用篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/29/MLeap介绍篇/">MLeap介绍篇</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/20/Spark ML Pipelines/">Spark ML Pipelines</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/31/记忆力杂谈/">记忆力杂谈</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/11/Java之新特性/">Java之新特性</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/09/10/NLP之知识图谱/">NLP之知识图谱</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/10/NLP之应用场景/">NLP之应用场景</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.baidu.com/" title="百度搜索" target="_blank">百度搜索</a><ul></ul><a href="http://www.google.com/" title="谷歌搜索" target="_blank">谷歌搜索</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">fangbb的博客.</a> Powered by<a rel="nofollow" target="_blank" href="https://fangbinbin.com"> fangbb.</a><br>
<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260773095'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1260773095%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1260773095'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s95.cnzz.com/z_stat.php%3Fid%3D1260773095%26online%3D1%26show%3Dline' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>